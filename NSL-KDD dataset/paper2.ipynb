{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit"
  },
  "interpreter": {
   "hash": "22e98dc126c11ed8b7da0abd0314319f11fb1123801a9053e96dbd9ca057f78a"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt;\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from kneed import DataGenerator, KneeLocator\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.naive_bayes import BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=r''\n",
    "traData = pd.read_csv(path+'trainingGroup.csv',index_col=None, header=None)\n",
    "#traData = pd.read_csv('D:\\\\drive\\\\publications_2017\\\\datasets\\\\NSL-KDD\\\\NSL-KDD\\\\testingData.csv'  , index_col = None , header = None)\n",
    "tesData = pd.read_csv(path+'testingGroup.csv',index_col=None, header=None)\n",
    "target = 41\n",
    "\n",
    "y_train = traData[[target]].values.reshape(len(traData)) \n",
    "x_train = preprocessing.normalize(traData.iloc[:,:-1])\n",
    "\n",
    "y_test = tesData[[target]].values.reshape(len(tesData)) \n",
    "x_test = preprocessing.normalize(tesData.iloc[:,:-1])\n",
    "\n",
    "def chooseObsMan(dic_f):\n",
    "    chosenIDs=np.array(())\n",
    "    for k,d in dic_f.items():\n",
    "        temp=np.where(y_train==k)[0]\n",
    "        z=np.random.choice(temp,dic_f[k],replace=False)\n",
    "        chosenIDs=np.concatenate((chosenIDs,z))\n",
    "    return np.int64(chosenIDs)\n",
    "def label_index(row,threshold=0):\n",
    "    \n",
    "    if threshold==0:\n",
    "        threshold=np.max(row)\n",
    "    temp_i=np.where(row>=threshold)[0]\n",
    "    if temp_i.shape[0]>0:\n",
    "        return temp_i[0]+1\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "labelled=np.zeros(x_train.shape[0])\n",
    "labelled[:]=-1\n",
    "li={1:60,2:60,3:30,4:10,5:10}\n",
    "labelledIndex=chooseObsMan(li)\n",
    "labelled[labelledIndex]=y_train[labelledIndex]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "BernoulliNB()"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "clf = BernoulliNB()\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = clf.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.8153175680502965\n"
     ]
    }
   ],
   "source": [
    "print((predicted == y_train).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                    normal           DoS         Probe         R2L        U2R\n0  Precision      0.904502      0.962465      0.294147    0.306367   0.144144\n1     Recall      0.907162      0.766564      0.512183    0.411055   0.615385\n2     Fscore      0.905830      0.853417      0.373686    0.351073   0.233577\n3    Support  67343.000000  45927.000000  11656.000000  995.000000  52.000000\n"
     ]
    }
   ],
   "source": [
    "matrices = metrics.precision_recall_fscore_support(y_train, predicted,labels=[1, 2, 3, 4, 5])\n",
    "resultsDataFrame = pd.DataFrame()\n",
    "for i in range(0,len(matrices)):\n",
    "    temp = pd.DataFrame([matrices[i]],columns=['normal','DoS','Probe','R2L','U2R'])\n",
    "    resultsDataFrame = resultsDataFrame.append(temp, ignore_index=True)\n",
    "resultsDataFrame.insert(0,'  ',['Precision','Recall','Fscore','Support'])\n",
    "print(resultsDataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[102708, 23265.0]\n"
     ]
    }
   ],
   "source": [
    "correctLabelled=metrics.accuracy_score(y_train, predicted,normalize=False)\n",
    "incorrectLabelled=sum(resultsDataFrame.iloc[3,1:]) - correctLabelled\n",
    "print([correctLabelled,incorrectLabelled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "        Total Correct Incorrect\nnormal  67343   61091      6252\nDoS     45927   35206     10721\nProbe   11656    5970      5686\nR2L       995     409       586\nU2R        52      32        20\n"
     ]
    }
   ],
   "source": [
    "numbers=resultsDataFrame.iloc[3,1:]\n",
    "correctLabelledForEachclass=resultsDataFrame.iloc[3,1:] *resultsDataFrame.iloc[1,1:]\n",
    "incorrectLabelledForEachclass=resultsDataFrame.iloc[3,1:]-correctLabelledForEachclass\n",
    "results1 = pd.DataFrame(columns = ['Total','Correct', 'Incorrect'])\n",
    "results1['Total'] = numbers\n",
    "results1['Correct'] = correctLabelledForEachclass\n",
    "results1['Incorrect'] = incorrectLabelledForEachclass\n",
    "print(results1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}